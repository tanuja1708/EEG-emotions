{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaYFyiHtb9dYKIqJoueYZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanuja1708/EEG-emotions/blob/main/Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pss2pHHhOzGF",
        "outputId": "85ab2e19-47af-436e-a641-edebc619b9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0KRequirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Collecting pykalman\n",
            "  Downloading pykalman-0.10.1-py2.py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Collecting scikit-base<0.13.0 (from pykalman)\n",
            "  Downloading scikit_base-0.12.2-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Downloading pykalman-0.10.1-py2.py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.5/248.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_base-0.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-base, pykalman, flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25 pykalman-0.10.1 scikit-base-0.12.2\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask\n",
        "!npm install -g localtunnel\n",
        "!pip install flask flask-ngrok tensorflow joblib pykalman scipy\n",
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with bandpass with ui\n",
        "\n",
        "from flask import Flask, jsonify\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "from scipy.signal import butter, filtfilt,welch\n",
        "from pykalman import KalmanFilter\n",
        "import subprocess\n",
        "import pywt\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "sampling_rate_original = 2500\n",
        "sampling_rate_final = 200\n",
        "segment_length = sampling_rate_final * 1\n",
        "\n",
        "freq_bands = {\n",
        "    \"Delta\": (1, 4),\n",
        "    \"Theta\": (4, 8),\n",
        "    \"Alpha\": (8, 14),\n",
        "    \"Beta\": (14, 31),\n",
        "    \"Gamma\": (31, 50)\n",
        "}\n",
        "\n",
        "# --- Kalman Filter Setup ---\n",
        "kf = KalmanFilter(\n",
        "    transition_matrices=[1],\n",
        "    observation_matrices=[1],\n",
        "    transition_covariance=0.2 * np.eye(1),\n",
        "    observation_covariance=0.5 * np.eye(1),\n",
        "    initial_state_mean=[20],\n",
        "    initial_state_covariance=5 * np.eye(1)\n",
        ")\n",
        "\n",
        "# --- Filtering & Downsampling ---\n",
        "def bandpass_filter(data, lowcut, highcut, fs):\n",
        "    nyq = 0.5 * fs\n",
        "    b, a = butter(4, [lowcut / nyq, highcut / nyq], btype='band')\n",
        "    return filtfilt(b, a, data)\n",
        "\n",
        "def downsample(signal, original_fs, target_fs):\n",
        "    factor = int(original_fs / target_fs)\n",
        "    return signal[::factor]\n",
        "\n",
        "# --- EEG Generator ---\n",
        "def generate_eeg():\n",
        "    t = np.linspace(0, 1, sampling_rate_original)\n",
        "    eeg = []\n",
        "    for _ in range(62):\n",
        "        alpha = np.random.uniform(40, 80) * np.sin(2 * np.pi * np.random.uniform(8, 13) * t)\n",
        "        beta = np.random.uniform(15, 35) * np.sin(2 * np.pi * np.random.uniform(14, 30) * t)\n",
        "        delta = np.random.uniform(1, 5) * np.sin(2 * np.pi * np.random.uniform(1, 3) * t)\n",
        "        theta = np.random.uniform(1, 5) * np.sin(2 * np.pi * np.random.uniform(4, 7) * t)\n",
        "        gamma = np.random.uniform(1, 5) * np.sin(2 * np.pi * np.random.uniform(31, 50) * t)\n",
        "        noise = np.random.normal(0, 3, t.shape)\n",
        "        signal = delta + theta + alpha + beta + gamma + noise\n",
        "        eeg.append(np.clip(signal, -70, 70))\n",
        "    return np.array(eeg)\n",
        "\n",
        "# --- MSPCA Denoising ---\n",
        "def mspca_denoise(eeg_data, wavelet='db4', level=4):\n",
        "    denoised_eeg = []\n",
        "    for channel in eeg_data:\n",
        "        coeffs = pywt.wavedec(channel, wavelet, level=level)\n",
        "        denoised_coeffs = []\n",
        "        for c in coeffs:\n",
        "            if len(c) > 1:\n",
        "                c = c.reshape(-1, 1)\n",
        "                pca = PCA(n_components=1)\n",
        "                transformed = pca.fit_transform(c)\n",
        "                reconstructed = pca.inverse_transform(transformed).flatten()\n",
        "                denoised_coeffs.append(reconstructed)\n",
        "            else:\n",
        "                denoised_coeffs.append(c)\n",
        "        denoised_signal = pywt.waverec(denoised_coeffs, wavelet)\n",
        "        denoised_eeg.append(denoised_signal[:len(channel)])\n",
        "    return np.array(denoised_eeg)\n",
        "\n",
        "# --- DE_LDS with Band-Split, Welch & MSPCA ---\n",
        "def extract_de_lds(eeg_data):\n",
        "    # 1) Downsample all channels\n",
        "    eeg_ds = [downsample(ch, sampling_rate_original, sampling_rate_final)\n",
        "              for ch in eeg_data]\n",
        "\n",
        "    de_features = []  # will become list of 62 vectors of length 5\n",
        "    for ch in eeg_ds:\n",
        "        channel_de = []\n",
        "\n",
        "        for low, high in freq_bands.values():\n",
        "            # 2) Narrow-band filter\n",
        "            sig_band = bandpass_filter(ch, low, high, sampling_rate_final)\n",
        "\n",
        "\n",
        "            # 3) MSPCA denoise _this_ 1D signal\n",
        "            denoised = mspca_denoise([sig_band])[0]\n",
        "\n",
        "            # 4) PSD → DE\n",
        "            freqs, psd = welch(denoised, fs=sampling_rate_final,\n",
        "                               nperseg=min(100, segment_length))\n",
        "            P_mean = np.mean(psd)\n",
        "            de_val = 0.5 * np.log(2 * np.pi * np.e * (P_mean + 1e-6))\n",
        "            channel_de.append(de_val)\n",
        "\n",
        "        # 5) Kalman smooth the 5-band DE vector\n",
        "        smoothed, _ = kf.filter(np.array(channel_de).reshape(-1, 1))\n",
        "        de_features.append(smoothed.flatten())\n",
        "\n",
        "    # 6) Normalize & flatten\n",
        "    feats = np.array(de_features)            # shape (62,5)\n",
        "    mn, mx = feats.min(), feats.max()\n",
        "    scaled = 15 + (feats - mn) / (mx - mn + 1e-8) * (27 - 15)\n",
        "    # print(scaled.flatten())\n",
        "    return scaled.flatten()\n",
        "\n",
        "@app.route('/predict', methods=['GET'])\n",
        "def predict_emotion():\n",
        "    eeg_data = generate_eeg()\n",
        "    features = extract_de_lds(eeg_data).reshape((1, 1,310))\n",
        "\n",
        "    # Load model and encoder\n",
        "    model = load_model('/content/eeg_emotion_gan_model.h5')\n",
        "    encoder = joblib.load('/content/eeg_label_encoder.pkl')\n",
        "\n",
        "    prediction = model.predict(features)\n",
        "    label = encoder.inverse_transform(np.argmax(prediction, axis=1))[0]\n",
        "\n",
        "    print(f\"Predicted Emotion: {label}\")\n",
        "    return jsonify({'emotion': label, 'eeg_data': eeg_data.tolist()})\n",
        "\n",
        "# --- LocalTunnel Setup ---\n",
        "def run_localtunnel():\n",
        "    subdomain = \"eegemotion\"\n",
        "    process = subprocess.Popen(['lt', '--port', '5000', '-s', subdomain], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in process.stdout:\n",
        "        print(line.decode('utf-8').strip())\n",
        "\n",
        "# --- Run App ---\n",
        "if __name__ == \"__main__\":\n",
        "    from threading import Thread\n",
        "    thread = Thread(target=run_localtunnel)\n",
        "    thread.start()\n",
        "    app.run(port=5000)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fxjg0MzPi0g",
        "outputId": "ededff45-7126-4a9d-d075-6790805e10ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://eegemotion.loca.lt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/May/2025 17:39:35] \"GET /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: Happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/May/2025 17:41:19] \"GET /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: Surprise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
            "Predicted Emotion: Happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/May/2025 17:41:32] \"GET /predict HTTP/1.1\" 200 -\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/May/2025 17:41:43] \"GET /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: Anger\n"
          ]
        }
      ]
    }
  ]
}