{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy7/X/P4fQrgLu7V04hjhw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanuja1708/EEG-emotions/blob/main/seed7_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the data\n",
        "csv_path = '/content/de_lds_with_labels(310).csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, :-1].values  # All columns except the last\n",
        "y = df.iloc[:, -1].values   # Last column as target\n",
        "\n",
        "\n",
        "# Encode emotion labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape X for LSTM: (samples, timesteps, features)\n",
        "# Assuming 1 timestep per row (since you reshaped timesteps * channels earlier)\n",
        "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
        "\n",
        "# One-hot encode labels for classification\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "print(\"x_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"✅ Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(r'D:\\de_lds_lstm_model.h5')\n",
        "print(\"✅ Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx89TT59mks2",
        "outputId": "922226ee-9aff-4ebb-fa36-c6074e73f346"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (55793, 1, 310)\n",
            "y_train shape: (55793, 7)\n",
            "x_test shape: (13949, 1, 310)\n",
            "y_test shape: (13949, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4136 - loss: 1.5425 - val_accuracy: 0.8344 - val_loss: 0.5648\n",
            "Epoch 2/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9070 - loss: 0.3714 - val_accuracy: 0.9871 - val_loss: 0.1092\n",
            "Epoch 3/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0802 - val_accuracy: 0.9972 - val_loss: 0.0278\n",
            "Epoch 4/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0436 - val_accuracy: 0.9970 - val_loss: 0.0191\n",
            "Epoch 5/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0288 - val_accuracy: 0.9970 - val_loss: 0.0194\n",
            "Epoch 6/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0080 - val_accuracy: 0.9999 - val_loss: 0.0053\n",
            "Epoch 7/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0456 - val_accuracy: 0.9998 - val_loss: 0.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0030 - val_accuracy: 0.9996 - val_loss: 0.0038\n",
            "Epoch 9/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0409 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 10/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 11/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.8692e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.5165e-04 - val_accuracy: 1.0000 - val_loss: 6.1598e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1347e-04 - val_accuracy: 1.0000 - val_loss: 4.5219e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7634e-04 - val_accuracy: 1.0000 - val_loss: 3.1656e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.6325e-04 - val_accuracy: 1.0000 - val_loss: 2.2251e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8844e-04 - val_accuracy: 1.0000 - val_loss: 1.5555e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.1012 - val_accuracy: 0.9894 - val_loss: 0.0361\n",
            "Epoch 18/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0145 - val_accuracy: 0.9994 - val_loss: 0.0043\n",
            "Epoch 19/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9504 - val_loss: 0.1586\n",
            "Epoch 20/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0682 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
            "Epoch 21/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 8.3444e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8386e-04 - val_accuracy: 1.0000 - val_loss: 5.3692e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4489e-04 - val_accuracy: 1.0000 - val_loss: 3.8141e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0866e-04 - val_accuracy: 1.0000 - val_loss: 2.8090e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.2401e-04 - val_accuracy: 1.0000 - val_loss: 1.9683e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9712 - loss: 0.1046 - val_accuracy: 0.9998 - val_loss: 0.0042\n",
            "Epoch 27/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 28/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9791 - val_loss: 0.0800\n",
            "Epoch 29/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 30/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4104e-04 - val_accuracy: 1.0000 - val_loss: 6.9505e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.3351e-04 - val_accuracy: 1.0000 - val_loss: 4.2132e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.2924e-04 - val_accuracy: 1.0000 - val_loss: 2.7269e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.3625e-04 - val_accuracy: 1.0000 - val_loss: 1.8975e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6105e-04 - val_accuracy: 1.0000 - val_loss: 1.3846e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.8595 - val_loss: 0.5397\n",
            "Epoch 36/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9638 - loss: 0.1228 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 37/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.4557e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.3243e-04 - val_accuracy: 1.0000 - val_loss: 4.7166e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.9342e-04 - val_accuracy: 1.0000 - val_loss: 3.1392e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.7403e-04 - val_accuracy: 1.0000 - val_loss: 2.2027e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8671e-04 - val_accuracy: 1.0000 - val_loss: 1.5482e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2904e-04 - val_accuracy: 1.0000 - val_loss: 1.0940e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.3682e-05 - val_accuracy: 1.0000 - val_loss: 7.6901e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0173 - val_accuracy: 0.9935 - val_loss: 0.0253\n",
            "Epoch 45/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 46/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 6.8841e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.9371e-04 - val_accuracy: 1.0000 - val_loss: 4.3337e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8599e-04 - val_accuracy: 1.0000 - val_loss: 2.9298e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5760e-04 - val_accuracy: 1.0000 - val_loss: 2.0131e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7682e-04 - val_accuracy: 1.0000 - val_loss: 1.4395e-04\n",
            "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4786e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Accuracy: 100.00%\n",
            "✅ Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the LabelEncoder\n",
        "joblib.dump(label_encoder, r'D:\\de_lds_label_encoder.pkl')\n",
        "print(\"✅ LabelEncoder saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhENave7qJ6t",
        "outputId": "8a200ff3-4dee-4790-e875-b44f560ec084"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LabelEncoder saved successfully!\n"
          ]
        }
      ]
    }
  ]
}